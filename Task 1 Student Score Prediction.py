# -*- coding: utf-8 -*-
"""Task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wyuZaD_cIBchGVzdWbTOqKcWHQO1Gg-R

Setup and Installation
"""

pip install pandas numpy matplotlib seaborn scikit-learn kagglehub

"""Import Libraries and Download Dataset"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import kagglehub
import os
import warnings
warnings.filterwarnings('ignore')

# Set style for plots
plt.style.use('default')
sns.set_palette("husl")

# Download the dataset
print("Downloading dataset from Kaggle...")
path = kagglehub.dataset_download("lainguyn123/student-performance-factors")
print("Path to dataset files:", path)

# Find the CSV file in the downloaded directory
csv_file = None
for file in os.listdir(path):
    if file.endswith('.csv'):
        csv_file = os.path.join(path, file)
        break

if csv_file:
    print(f"Found CSV file: {csv_file}")
    df = pd.read_csv(csv_file)
else:
    print("CSV file not found in the dataset directory. Using synthetic data for demonstration.")
    # Create synthetic data
    np.random.seed(42)
    n_students = 200
    study_hours = np.random.normal(5, 2, n_students)
    study_hours = np.clip(study_hours, 1, 10)
    sleep_hours = np.random.normal(7, 1.5, n_students)
    sleep_hours = np.clip(sleep_hours, 4, 10)
    participation = np.random.uniform(0, 100, n_students)

    scores = 30 + 5 * study_hours + 2 * sleep_hours + 0.1 * participation + np.random.normal(0, 5, n_students)
    scores = np.clip(scores, 0, 100)

    df = pd.DataFrame({
        'Hours Studied': study_hours,
        'Sleep Hours': sleep_hours,
        'Sample Question Papers Practiced': participation,
        'Performance Index': scores
    })

"""Data Exploration and Cleaning"""

# Display dataset info
print("\nDataset Overview:")
print(f"Shape: {df.shape}")
print("\nFirst 5 rows:")
print(df.head())
print("\nDataset Information:")
print(df.info())
print("\nDescriptive Statistics:")
print(df.describe())
print("\nMissing Values:")
print(df.isnull().sum())

# Data Cleaning - Handle missing values if any
if df.isnull().sum().sum() > 0:
    print("\nHandling missing values...")
    # Fill numerical missing values with median
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())

    # Check if there are any categorical columns with missing values
    categorical_cols = df.select_dtypes(include=['object']).columns
    for col in categorical_cols:
        if df[col].isnull().sum() > 0:
            df[col] = df[col].fillna(df[col].mode()[0])

# Standardize column names
column_mapping = {
    'Hours Studied': 'study_hours',
    'Sleep Hours': 'sleep_hours',
    'Sample Question Papers Practiced': 'practice_hours',
    'Performance Index': 'score',
    'Extracurricular Activities': 'extracurricular'
}

# Apply mapping for any columns that exist
for old_name, new_name in column_mapping.items():
    if old_name in df.columns:
        df.rename(columns={old_name: new_name}, inplace=True)

# If we don't have the expected columns, create them
if 'study_hours' not in df.columns:
    # Find a column that might represent study hours
    for col in df.columns:
        if 'hour' in col.lower() or 'study' in col.lower():
            df.rename(columns={col: 'study_hours'}, inplace=True)
            break

if 'score' not in df.columns:
    # Find a column that might represent scores
    for col in df.columns:
        if 'score' in col.lower() or 'performance' in col.lower() or 'grade' in col.lower():
            df.rename(columns={col: 'score'}, inplace=True)
            break

# If we still don't have the required columns, create synthetic ones
if 'study_hours' not in df.columns or 'score' not in df.columns:
    print("Creating synthetic study_hours and score columns for demonstration...")
    df['study_hours'] = np.random.normal(5, 2, len(df))
    df['study_hours'] = np.clip(df['study_hours'], 1, 10)
    df['score'] = 30 + 5 * df['study_hours'] + np.random.normal(0, 5, len(df))
    df['score'] = np.clip(df['score'], 0, 100)

""" Data Visualization"""

# Data Visualization
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('Data Distribution and Relationships', fontsize=16)

# Distribution of study hours
axes[0, 0].hist(df['study_hours'], bins=15, edgecolor='black', alpha=0.7)
axes[0, 0].set_title('Distribution of Study Hours')
axes[0, 0].set_xlabel('Study Hours')
axes[0, 0].set_ylabel('Frequency')

# Distribution of scores
axes[0, 1].hist(df['score'], bins=15, edgecolor='black', alpha=0.7, color='orange')
axes[0, 1].set_title('Distribution of Scores')
axes[0, 1].set_xlabel('Score')
axes[0, 1].set_ylabel('Frequency')

# Study hours vs scores
axes[1, 0].scatter(df['study_hours'], df['score'], alpha=0.6)
axes[1, 0].set_title('Study Hours vs Scores')
axes[1, 0].set_xlabel('Study Hours')
axes[1, 0].set_ylabel('Score')

# Correlation heatmap
numeric_df = df.select_dtypes(include=[np.number])
if len(numeric_df.columns) > 1:
    corr = numeric_df.corr()
    im = axes[1, 1].imshow(corr, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)
    axes[1, 1].set_title('Correlation Heatmap')
    axes[1, 1].set_xticks(range(len(corr.columns)))
    axes[1, 1].set_yticks(range(len(corr.columns)))
    axes[1, 1].set_xticklabels(corr.columns, rotation=45)
    axes[1, 1].set_yticklabels(corr.columns)

    # Add correlation values to heatmap
    for i in range(len(corr.columns)):
        for j in range(len(corr.columns)):
            text = axes[1, 1].text(j, i, f'{corr.iloc[i, j]:.2f}',
                           ha="center", va="center", color="black")
else:
    axes[1, 1].text(0.5, 0.5, 'Not enough numeric columns for correlation matrix',
                    ha='center', va='center', transform=axes[1, 1].transAxes)
    axes[1, 1].set_title('Correlation Heatmap')

plt.tight_layout()
plt.show()

"""Linear Regression Model"""

# Prepare data for modeling
X = df[['study_hours']]  # Using only study hours initially
y = df['score']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training set size: {X_train.shape[0]}")
print(f"Testing set size: {X_test.shape[0]}")

# Train linear regression model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Make predictions
y_pred_lr = lr_model.predict(X_test)

# Evaluate the model
mse_lr = mean_squared_error(y_test, y_pred_lr)
rmse_lr = np.sqrt(mse_lr)
mae_lr = mean_absolute_error(y_test, y_pred_lr)
r2_lr = r2_score(y_test, y_pred_lr)

print("\nLinear Regression Results:")
print(f"Slope (Coefficient): {lr_model.coef_[0]:.4f}")
print(f"Intercept: {lr_model.intercept_:.4f}")
print(f"Mean Squared Error: {mse_lr:.4f}")
print(f"Root Mean Squared Error: {rmse_lr:.4f}")
print(f"Mean Absolute Error: {mae_lr:.4f}")
print(f"R-squared: {r2_lr:.4f}")

# Visualize linear regression results
plt.figure(figsize=(10, 6))
plt.scatter(X_test, y_test, color='blue', alpha=0.6, label='Actual')
plt.scatter(X_test, y_pred_lr, color='red', alpha=0.6, label='Predicted')
plt.plot(X_test, y_pred_lr, color='red', linewidth=2)

# Add regression line for the entire dataset
x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
y_range = lr_model.predict(x_range)
plt.plot(x_range, y_range, color='green', linewidth=2, label='Regression Line')

plt.title('Linear Regression: Study Hours vs Score')
plt.xlabel('Study Hours')
plt.ylabel('Score')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

"""Polynomial Regression (Bonus)"""

# Bonus: Polynomial Regression
print("\n" + "="*50)
print("BONUS: POLYNOMIAL REGRESSION")
print("="*50)

# Create polynomial features
poly = PolynomialFeatures(degree=2)
X_poly_train = poly.fit_transform(X_train)
X_poly_test = poly.transform(X_test)

# Train polynomial regression model
poly_model = LinearRegression()
poly_model.fit(X_poly_train, y_train)

# Make predictions
y_pred_poly = poly_model.predict(X_poly_test)

# Evaluate the model
mse_poly = mean_squared_error(y_test, y_pred_poly)
rmse_poly = np.sqrt(mse_poly)
mae_poly = mean_absolute_error(y_test, y_pred_poly)
r2_poly = r2_score(y_test, y_pred_poly)

print("\nPolynomial Regression (Degree=2) Results:")
print(f"Coefficients: {poly_model.coef_}")
print(f"Intercept: {poly_model.intercept_:.4f}")
print(f"Mean Squared Error: {mse_poly:.4f}")
print(f"Root Mean Squared Error: {rmse_poly:.4f}")
print(f"Mean Absolute Error: {mae_poly:.4f}")
print(f"R-squared: {r2_poly:.4f}")

# Visualize polynomial regression results
plt.figure(figsize=(10, 6))
plt.scatter(X_test, y_test, color='blue', alpha=0.6, label='Actual')
plt.scatter(X_test, y_pred_poly, color='purple', alpha=0.6, label='Predicted (Poly)')

# Sort values for smooth curve
X_sorted = np.sort(X_test, axis=0)
y_poly_sorted = poly_model.predict(poly.transform(X_sorted))
plt.plot(X_sorted, y_poly_sorted, color='purple', linewidth=2, label='Polynomial Regression')

# Compare with linear regression
plt.plot(x_range, y_range, color='green', linewidth=2, label='Linear Regression')

plt.title('Polynomial vs Linear Regression: Study Hours vs Score')
plt.xlabel('Study Hours')
plt.ylabel('Score')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

"""Feature Combinations Experiment (Bonus)"""

# Bonus: Experiment with different feature combinations
print("\n" + "="*50)
print("BONUS: FEATURE COMBINATIONS")
print("="*50)

# Get all numeric features except the target
numeric_features = [col for col in numeric_df.columns if col != 'score']

# Define different feature combinations
feature_sets = {
    'Only Study Hours': ['study_hours'],
}

# Add other feature combinations if available
if 'sleep_hours' in numeric_df.columns:
    feature_sets['Study + Sleep Hours'] = ['study_hours', 'sleep_hours']
if 'practice_hours' in numeric_df.columns:
    feature_sets['Study + Practice Hours'] = ['study_hours', 'practice_hours']

# Add all available numeric features (except target)
if len(numeric_features) > 1:
    feature_sets['All Numeric Features'] = [f for f in numeric_features if f != 'score']

results = []

for feature_name, features in feature_sets.items():
    X = df[features]
    y = df['score']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = LinearRegression()
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    results.append({
        'Features': feature_name,
        'R-squared': r2,
        'RMSE': rmse,
        'MSE': mse
    })

    print(f"\n{feature_name}:")
    print(f"  R-squared: {r2:.4f}")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  MSE: {mse:.4f}")

# Create a comparison DataFrame
results_df = pd.DataFrame(results)
print("\nFeature Combination Comparison:")
print(results_df)

# Visualize comparison
if len(results_df) > 0:
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

    # R-squared comparison
    ax1.bar(results_df['Features'], results_df['R-squared'], color='skyblue')
    ax1.set_title('R-squared by Feature Combination')
    ax1.set_ylabel('R-squared')
    ax1.tick_params(axis='x', rotation=45)

    # RMSE comparison
    ax2.bar(results_df['Features'], results_df['RMSE'], color='lightcoral')
    ax2.set_title('RMSE by Feature Combination')
    ax2.set_ylabel('RMSE')
    ax2.tick_params(axis='x', rotation=45)

    plt.tight_layout()
    plt.show()

    # Final conclusion
    if len(results_df) > 0:
        best_model = results_df.loc[results_df['R-squared'].idxmax()]
        print(f"\nBest performing model: {best_model['Features']} with R-squared = {best_model['R-squared']:.4f}")
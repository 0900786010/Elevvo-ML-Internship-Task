# -*- coding: utf-8 -*-
"""Task6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jBnz3199dgUlvpleEZzGnkP_RuByY6q5

Download the dataset
"""

import kagglehub
data_path = kagglehub.dataset_download('andradaolteanu/gtzan-dataset-music-genre-classification')
print('Data source import complete.')

"""Set dataset path correctly


"""

dataset_path = os.path.join(data_path, "Data/genres_original")
print("Dataset Path:", dataset_path)

"""Import libraries"""

import os
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, accuracy_score
from sklearn.ensemble import RandomForestClassifier

"""Extract MFCC features"""

def extract_features(file_path, max_pad_len=174):
    try:
        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')
        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
        pad_width = max_pad_len - mfccs.shape[1]
        if pad_width > 0:
            mfccs = np.pad(mfccs, pad_width=((0,0),(0,pad_width)), mode='constant')
        else:
            mfccs = mfccs[:, :max_pad_len]
        return mfccs.flatten()
    except Exception as e:
        print("Error extracting from:", file_path, e)
        return None

"""Prepare dataset"""

labels = []
features = []

genres = os.listdir(dataset_path)
for genre in genres:
    genre_path = os.path.join(dataset_path, genre)
    if not os.path.isdir(genre_path):
        continue
    for file in os.listdir(genre_path):
        file_path = os.path.join(genre_path, file)
        data = extract_features(file_path)
        if data is not None:
            features.append(data)
            labels.append(genre)

X = np.array(features)
y = np.array(labels)

print("Features shape:", X.shape)
print("Labels shape:", y.shape)

"""Encode labels"""

encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

"""Train-test split"""

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)
model = RandomForestClassifier(n_estimators=200, random_state=42)
model.fit(X_train, y_train)

"""Scale features"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""Train model (Random Forest here, you can try others like XGBoost or SVM)

Evaluate
"""

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=encoder.classes_))
# -*- coding: utf-8 -*-
"""Task5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-zNO9gARDWr5g9b2qINGqYoIIvGEiPIh

Install Required Libraries
"""

!pip install pandas numpy scikit-learn scipy surprise kaggle

""" Import Necessary Libraries"""

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# For SVD
from scipy.sparse.linalg import svds

print("All libraries imported successfully!")

"""Load the Dataset from URLs"""

# URLs for the MovieLens 100K dataset
u_data_url = "https://files.grouplens.org/datasets/movielens/ml-100k/u.data"
u_item_url = "https://files.grouplens.org/datasets/movielens/ml-100k/u.item"
u_user_url = "https://files.grouplens.org/datasets/movielens/ml-100k/u.user"

# Load the data
ratings = pd.read_csv(u_data_url, sep='\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])
movies = pd.read_csv(u_item_url, sep='|', encoding='latin-1',
                     names=['movie_id', 'title', 'release_date', 'video_release_date',
                            'imdb_url', 'unknown', 'Action', 'Adventure', 'Animation',
                            'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',
                            'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',
                            'Thriller', 'War', 'Western'])
users = pd.read_csv(u_user_url, sep='|', names=['user_id', 'age', 'gender', 'occupation', 'zip_code'])

print("Data loaded successfully!")
print(f"Users: {users.shape[0]}, Ratings: {ratings.shape[0]}, Movies: {movies.shape[0]}")

"""Data Exploration and Preprocessing"""

# Display basic information about the datasets
print("Users dataset:")
print(users.head())
print("\nRatings dataset:")
print(ratings.head())
print("\nMovies dataset:")
print(movies[['movie_id', 'title']].head())

# Check for missing values
print("\nMissing values:")
print(f"Users: {users.isnull().sum().sum()}")
print(f"Ratings: {ratings.isnull().sum().sum()}")
print(f"Movies: {movies.isnull().sum().sum()}")

# Basic statistics
print("\nRating distribution:")
print(ratings['rating'].value_counts().sort_index())

# Merge datasets to have a comprehensive view
movie_ratings = pd.merge(ratings, movies[['movie_id', 'title']], on='movie_id')
movie_ratings = pd.merge(movie_ratings, users[['user_id', 'age', 'gender']], on='user_id')

print(f"\nFinal merged dataset shape: {movie_ratings.shape}")
print(movie_ratings.head())

"""Create User-Item Matrix"""

# Create user-item matrix
user_item_matrix = ratings.pivot(index='user_id', columns='movie_id', values='rating')

# Fill NaN values with 0 (indicating no rating)
user_item_matrix = user_item_matrix.fillna(0)

print(f"User-Item Matrix shape: {user_item_matrix.shape}")
print(user_item_matrix.head())

"""User-Based Collaborative Filtering"""

def calculate_user_similarity(user_item_matrix):
    """Calculate cosine similarity between users"""
    user_similarity = cosine_similarity(user_item_matrix)
    user_similarity_df = pd.DataFrame(user_similarity,
                                     index=user_item_matrix.index,
                                     columns=user_item_matrix.index)
    return user_similarity_df

# Calculate user similarity
user_similarity = calculate_user_similarity(user_item_matrix)
print("User similarity matrix created!")
print(user_similarity.head())

""" Recommendation Function for User-Based CF"""

def recommend_movies_user_based(user_id, user_item_matrix, user_similarity, movies, n_similar_users=10, n_recommendations=5):
    """Generate movie recommendations for a user based on similar users"""

    # Get the user's ratings
    user_ratings = user_item_matrix.loc[user_id]

    # Find similar users
    similar_users = user_similarity[user_id].sort_values(ascending=False)[1:n_similar_users+1]

    # Get movies rated by similar users but not by the target user
    similar_users_ratings = user_item_matrix.loc[similar_users.index]

    # Calculate weighted average of ratings from similar users
    movie_scores = {}
    movie_counts = {}

    for other_user_id, similarity_score in similar_users.items():
        other_user_ratings = user_item_matrix.loc[other_user_id]

        for movie_id, rating in other_user_ratings.items():
            if rating > 0 and user_ratings[movie_id] == 0:  # Movie not rated by target user
                if movie_id not in movie_scores:
                    movie_scores[movie_id] = 0
                    movie_counts[movie_id] = 0

                movie_scores[movie_id] += rating * similarity_score
                movie_counts[movie_id] += similarity_score

    # Calculate average scores
    movie_avg_scores = {}
    for movie_id, total_score in movie_scores.items():
        if movie_counts[movie_id] > 0:
            movie_avg_scores[movie_id] = total_score / movie_counts[movie_id]

    # Sort movies by average score
    recommended_movies = sorted(movie_avg_scores.items(), key=lambda x: x[1], reverse=True)[:n_recommendations]

    # Get movie details
    recommendations = []
    for movie_id, score in recommended_movies:
        movie_info = movies[movies['movie_id'] == movie_id].iloc[0]
        recommendations.append({
            'movie_id': movie_id,
            'title': movie_info['title'],
            'predicted_rating': round(score, 2)
        })

    return pd.DataFrame(recommendations)

# Test the recommendation function
user_id = 1
recommendations = recommend_movies_user_based(user_id, user_item_matrix, user_similarity, movies)
print(f"Top recommendations for user {user_id}:")
print(recommendations)

""" Evaluation with Precision at K"""

def evaluate_precision_at_k(user_item_matrix, user_similarity, movies, k=5, test_size=0.2, n_users=50):
    """Evaluate the recommendation system using precision at K"""

    # Select a subset of users for evaluation
    user_sample = np.random.choice(user_item_matrix.index, size=min(n_users, len(user_item_matrix.index)), replace=False)

    precision_scores = []

    for user_id in user_sample:
        # Create a train-test split for this user
        user_ratings = user_item_matrix.loc[user_id]
        rated_movies = user_ratings[user_ratings > 0].index.tolist()

        if len(rated_movies) < 10:  # Skip users with too few ratings
            continue

        # Split into train and test
        train_movies, test_movies = train_test_split(rated_movies, test_size=test_size, random_state=42)

        # Create a modified user-item matrix for training
        train_matrix = user_item_matrix.copy()
        for movie_id in test_movies:
            train_matrix.loc[user_id, movie_id] = 0

        # Recalculate similarity for the training matrix
        train_similarity = calculate_user_similarity(train_matrix)

        # Generate recommendations
        recommendations = recommend_movies_user_based(user_id, train_matrix, train_similarity, movies, n_recommendations=k)
        recommended_movies = recommendations['movie_id'].tolist()

        # Calculate precision at K
        relevant_items = set(test_movies)
        recommended_items = set(recommended_movies)
        true_positives = len(relevant_items.intersection(recommended_items))
        precision = true_positives / k if k > 0 else 0

        precision_scores.append(precision)

    # Calculate average precision
    avg_precision = np.mean(precision_scores) if precision_scores else 0
    return avg_precision

# Evaluate the system
precision = evaluate_precision_at_k(user_item_matrix, user_similarity, movies, k=5)
print(f"Precision at 5: {precision:.4f}")

"""Item-Based Collaborative Filtering (Bonus)"""

def calculate_item_similarity(user_item_matrix):
    """Calculate cosine similarity between items"""
    item_similarity = cosine_similarity(user_item_matrix.T)
    item_similarity_df = pd.DataFrame(item_similarity,
                                     index=user_item_matrix.columns,
                                     columns=user_item_matrix.columns)
    return item_similarity_df

def recommend_movies_item_based(user_id, user_item_matrix, item_similarity, movies, n_recommendations=5):
    """Generate movie recommendations for a user based on item similarity"""

    # Get the user's ratings
    user_ratings = user_item_matrix.loc[user_id]

    # Find movies the user has rated
    rated_movies = user_ratings[user_ratings > 0].index

    # Calculate predicted ratings for unrated movies
    movie_scores = {}

    for movie_id in user_item_matrix.columns:
        if user_ratings[movie_id] == 0:  # Movie not rated by user
            # Find similar movies that the user has rated
            similar_movies = item_similarity[movie_id].sort_values(ascending=False)[1:11]  # Top 10 similar movies

            numerator = 0
            denominator = 0

            for similar_movie_id, similarity in similar_movies.items():
                if similar_movie_id in rated_movies and similarity > 0:
                    rating = user_ratings[similar_movie_id]
                    numerator += rating * similarity
                    denominator += similarity

            if denominator > 0:
                movie_scores[movie_id] = numerator / denominator

    # Sort movies by predicted rating
    recommended_movies = sorted(movie_scores.items(), key=lambda x: x[1], reverse=True)[:n_recommendations]

    # Get movie details
    recommendations = []
    for movie_id, score in recommended_movies:
        movie_info = movies[movies['movie_id'] == movie_id].iloc[0]
        recommendations.append({
            'movie_id': movie_id,
            'title': movie_info['title'],
            'predicted_rating': round(score, 2)
        })

    return pd.DataFrame(recommendations)

# Calculate item similarity
item_similarity = calculate_item_similarity(user_item_matrix)
print("Item similarity matrix created!")

# Test item-based recommendations
user_id = 1
item_based_recommendations = recommend_movies_item_based(user_id, user_item_matrix, item_similarity, movies)
print(f"Item-based recommendations for user {user_id}:")
print(item_based_recommendations)

"""Matrix Factorization with SVD (Bonus)"""

def matrix_factorization_svd(user_item_matrix, k=50):
    """Perform matrix factorization using SVD"""
    # Convert to numpy array
    R = user_item_matrix.values

    # Normalize by user means
    user_ratings_mean = np.mean(R, axis=1)
    R_demeaned = R - user_ratings_mean.reshape(-1, 1)

    # Perform SVD
    U, sigma, Vt = svds(R_demeaned, k=k)

    # Convert sigma to diagonal matrix
    sigma = np.diag(sigma)

    # Make predictions
    all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)

    # Convert back to DataFrame
    preds_df = pd.DataFrame(all_user_predicted_ratings,
                           index=user_item_matrix.index,
                           columns=user_item_matrix.columns)

    return preds_df

def recommend_movies_svd(user_id, user_item_matrix, preds_df, movies, n_recommendations=5):
    """Generate movie recommendations using SVD predictions"""

    # Get the user's predictions
    user_predictions = preds_df.loc[user_id]

    # Get the user's original ratings
    user_ratings = user_item_matrix.loc[user_id]

    # Find movies the user hasn't rated yet
    unrated_movies = user_ratings[user_ratings == 0].index

    # Get predicted ratings for unrated movies
    recommendations = user_predictions[unrated_movies].sort_values(ascending=False)[:n_recommendations]

    # Get movie details
    recommendation_list = []
    for movie_id, predicted_rating in recommendations.items():
        movie_info = movies[movies['movie_id'] == movie_id].iloc[0]
        recommendation_list.append({
            'movie_id': movie_id,
            'title': movie_info['title'],
            'predicted_rating': round(predicted_rating, 2)
        })

    return pd.DataFrame(recommendation_list)

# Perform SVD
preds_df = matrix_factorization_svd(user_item_matrix, k=50)
print("SVD completed!")

# Test SVD recommendations
user_id = 1
svd_recommendations = recommend_movies_svd(user_id, user_item_matrix, preds_df, movies)
print(f"SVD-based recommendations for user {user_id}:")
print(svd_recommendations)

"""Comparison and Final Evaluation"""

# Compare recommendations from all three methods
print("=== COMPARISON OF RECOMMENDATION APPROACHES ===")
print(f"\nUser-Based Collaborative Filtering for user {user_id}:")
user_based_rec = recommend_movies_user_based(user_id, user_item_matrix, user_similarity, movies)
print(user_based_rec)

print(f"\nItem-Based Collaborative Filtering for user {user_id}:")
item_based_rec = recommend_movies_item_based(user_id, user_item_matrix, item_similarity, movies)
print(item_based_rec)

print(f"\nSVD-Based Recommendations for user {user_id}:")
svd_rec = recommend_movies_svd(user_id, user_item_matrix, preds_df, movies)
print(svd_rec)

# Evaluate precision for user-based method
print("\n=== EVALUATION ===")
user_based_precision = evaluate_precision_at_k(user_item_matrix, user_similarity, movies, k=5)
print(f"User-Based Precision at 5: {user_based_precision:.4f}")

# Create a function to evaluate item-based precision
def evaluate_item_based_precision(user_item_matrix, item_similarity, movies, k=5, test_size=0.2, n_users=50):
    """Evaluate the item-based recommendation system using precision at K"""

    # Select a subset of users for evaluation
    user_sample = np.random.choice(user_item_matrix.index, size=min(n_users, len(user_item_matrix.index)), replace=False)

    precision_scores = []

    for user_id in user_sample:
        # Create a train-test split for this user
        user_ratings = user_item_matrix.loc[user_id]
        rated_movies = user_ratings[user_ratings > 0].index.tolist()

        if len(rated_movies) < 10:  # Skip users with too few ratings
            continue

        # Split into train and test
        train_movies, test_movies = train_test_split(rated_movies, test_size=test_size, random_state=42)

        # Create a modified user-item matrix for training
        train_matrix = user_item_matrix.copy()
        for movie_id in test_movies:
            train_matrix.loc[user_id, movie_id] = 0

        # Recalculate similarity for the training matrix
        train_item_similarity = calculate_item_similarity(train_matrix)

        # Generate recommendations
        recommendations = recommend_movies_item_based(user_id, train_matrix, train_item_similarity, movies, n_recommendations=k)
        recommended_movies = recommendations['movie_id'].tolist()

        # Calculate precision at K
        relevant_items = set(test_movies)
        recommended_items = set(recommended_movies)
        true_positives = len(relevant_items.intersection(recommended_items))
        precision = true_positives / k if k > 0 else 0

        precision_scores.append(precision)

    # Calculate average precision
    avg_precision = np.mean(precision_scores) if precision_scores else 0
    return avg_precision

# Evaluate item-based precision
item_based_precision = evaluate_item_based_precision(user_item_matrix, item_similarity, movies, k=5)
print(f"Item-Based Precision at 5: {item_based_precision:.4f}")
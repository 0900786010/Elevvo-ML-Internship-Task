# -*- coding: utf-8 -*-
"""Task4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a13np1QxT3tqL_LSxo8SzVbtnZfr3xF3

Import Required Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from imblearn.over_sampling import SMOTE
import kagglehub
import warnings
warnings.filterwarnings('ignore')

# Set random seed for reproducibility
np.random.seed(42)

"""DOWNLOAD AND LOAD DATASET

"""

print("Downloading dataset from Kaggle...")
path = kagglehub.dataset_download("architsharma01/loan-approval-prediction-dataset")
print(f"Dataset downloaded to: {path}")

# Load the dataset
print("Loading dataset...")
df = pd.read_csv(path + '/loan_approval_dataset.csv')
print(f"Dataset shape: {df.shape}")

"""EXPLORATORY DATA ANALYSIS

"""

print("\nDataset Info:")
print(df.info())

print("\nFirst 5 rows of the dataset:")
print(df.head())

print("\nColumn names:")
print(df.columns.tolist())

print("\nMissing values in each column:")
print(df.isnull().sum())

# Check the distribution of the target variable
print("\nChecking for target variable...")
# The target column might have a different name, let's find it
possible_target_columns = ['loan_status', 'status', 'approval_status', 'loan_approved', 'approved']
target_column = None

for col in possible_target_columns:
    if col in df.columns:
        target_column = col
        break

if target_column is None:
    # If none of the expected names match, look for a binary column
    for col in df.columns:
        if df[col].nunique() == 2:
            target_column = col
            break

if target_column is None:
    # If still not found, use the last column
    target_column = df.columns[-1]

print(f"Using '{target_column}' as the target variable")

print(f"\nTarget variable distribution ({target_column}):")
print(df[target_column].value_counts())
print(df[target_column].value_counts(normalize=True))

"""DATA PREPROCESSING AND CLEANING"""

df_clean = df.copy()

# Remove any duplicate rows
initial_count = len(df_clean)
df_clean = df_clean.drop_duplicates()
final_count = len(df_clean)
print(f"Removed {initial_count - final_count} duplicate rows")

# Handle missing values
print("\nHandling missing values...")

# Identify numerical and categorical columns
numerical_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()
categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()

# Remove target variable from feature lists
if target_column in numerical_cols:
    numerical_cols.remove(target_column)
if target_column in categorical_cols:
    categorical_cols.remove(target_column)

print(f"Numerical columns: {numerical_cols}")
print(f"Categorical columns: {categorical_cols}")

# Impute missing values for numerical columns with median
if numerical_cols:
    num_imputer = SimpleImputer(strategy='median')
    df_clean[numerical_cols] = num_imputer.fit_transform(df_clean[numerical_cols])

# Impute missing values for categorical columns with mode
if categorical_cols:
    cat_imputer = SimpleImputer(strategy='most_frequent')
    df_clean[categorical_cols] = cat_imputer.fit_transform(df_clean[categorical_cols])

print("Missing values after imputation:")
print(df_clean.isnull().sum())

"""ENCODING CATEGORICAL FEATURES"""

label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df_clean[col] = le.fit_transform(df_clean[col].astype(str))
    label_encoders[col] = le
    print(f"Encoded {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}")

# Encode the target variable
target_encoder = LabelEncoder()
df_clean[target_column] = target_encoder.fit_transform(df_clean[target_column].astype(str))
print(f"Encoded target variable ({target_column}): {dict(zip(target_encoder.classes_, target_encoder.transform(target_encoder.classes_)))}")

# Display the cleaned dataset
print("\nCleaned dataset after encoding:")
print(df_clean.head())

"""PREPARING DATA FOR MODELING"""

# Separate features and target
X = df_clean.drop(target_column, axis=1)
y = df_clean[target_column]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Scale the numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"Training set shape: {X_train.shape}")
print(f"Testing set shape: {X_test.shape}")
print(f"Class distribution in training set: {np.bincount(y_train)}")
print(f"Class distribution in testing set: {np.bincount(y_test)}")

"""HANDLING CLASS IMBALANCE WITH SMOTE"""

# Apply SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)

print(f"Class distribution before SMOTE: {np.bincount(y_train)}")
print(f"Class distribution after SMOTE: {np.bincount(y_train_resampled)}")

"""MODEL TRAINING AND EVALUATION"""

# Initialize models
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(random_state=42)
}

# Train and evaluate each model
results = {}

for name, model in models.items():
    print(f"\n{'-'*40}")
    print(f"Training and evaluating {name}")
    print(f"{'-'*40}")

    # Train the model
    if name == 'Logistic Regression':
        model.fit(X_train_resampled, y_train_resampled)
    else:
        model.fit(X_train_scaled, y_train)

    # Make predictions
    y_pred = model.predict(X_test_scaled)

    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    # Store results
    results[name] = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }

    # Print results
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")

    # Print classification report
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=target_encoder.classes_))

    # Print confusion matrix
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))

"""RESULTS COMPARISON AND CONCLUSION"""

# Create a comparison DataFrame
results_df = pd.DataFrame.from_dict(results, orient='index')
print("\nModel Performance Comparison:")
print(results_df)

# Visualize the results
fig, ax = plt.subplots(2, 2, figsize=(15, 10))
metrics = ['accuracy', 'precision', 'recall', 'f1']
titles = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

for i, metric in enumerate(metrics):
    row, col = i // 2, i % 2
    results_df[metric].plot(kind='bar', ax=ax[row, col])
    ax[row, col].set_title(titles[i])
    ax[row, col].set_ylim(0, 1)
    ax[row, col].set_ylabel('Score')

plt.tight_layout()
plt.savefig('model_performance_comparison.png')
plt.show()

# Determine the best model based on F1-score
best_model_name = results_df['f1'].idxmax()
best_model_score = results_df['f1'].max()

print(f"\nBest model: {best_model_name} with F1-Score: {best_model_score:.4f}")

# Feature importance for Decision Tree
if 'Decision Tree' in models:
    dt_model = models['Decision Tree']
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': dt_model.feature_importances_
    }).sort_values('importance', ascending=False)

    print("\nDecision Tree Feature Importance:")
    print(feature_importance)

    # Plot feature importance
    plt.figure(figsize=(10, 6))
    sns.barplot(x='importance', y='feature', data=feature_importance)
    plt.title('Decision Tree Feature Importance')
    plt.tight_layout()
    plt.savefig('feature_importance.png')
    plt.show()

print("\nTask completed successfully!")